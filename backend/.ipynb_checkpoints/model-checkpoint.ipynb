{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a245fe-c2be-45a2-84a0-12d4555e0b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ced231-e986-46ef-8b86-98efabbed8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc = pd.read_csv('BTC-USD.csv')\n",
    "eth = pd.read_csv('ETH-USD.csv')\n",
    "spy = pd.read_csv('SPY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f7b7b5-16bb-4808-957d-e064e4829efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e724a7-4169-4759-a69c-b1f2345252f1",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049d1c7a-ea08-4e07-adae-2ed6d0ee5059",
   "metadata": {},
   "source": [
    "### Convert column name to perspective column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a16a302-2b51-4772-b77e-1dc63d29fab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bea7db-107e-44b4-9259-add018938adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a894c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for any missing data\n",
    "print(btc.isna().sum())\n",
    "print(eth.isna().sum())\n",
    "print(spy.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7f406-6d57-4ecd-9c59-f3709c0e7933",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in btc.columns:\n",
    "    if i != 'Date':\n",
    "        btc['btc' +i] = btc[i]\n",
    "        btc = btc.drop(i, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7841e8ef-e4d7-4036-983b-d9675eb1002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in eth.columns:\n",
    "    if i != 'Date':\n",
    "        eth['eth' +i] = eth[i]\n",
    "        eth = eth.drop(i, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e24b1b-c787-4a24-b413-179950e74289",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in spy.columns:\n",
    "    if i != 'Date':\n",
    "        spy['spy' +i] = spy[i]\n",
    "        spy = spy.drop(i, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a7caeb-3ef1-4b2d-af1d-62e3a45f2aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eth.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad906c24-5280-4e31-bd25-e204039880b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70925a56-e890-437d-bca2-14eb24a59c98",
   "metadata": {},
   "source": [
    "https://realpython.com/pandas-merge-join-and-concat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34791bec-995d-4f76-970f-bc84bc28e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(btc, eth, on = [\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b1047f-6c71-4989-9dd4-8d10a759f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9447fed3-bab6-4773-ba47-ad2c97b65a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, spy, on = ['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d99a1b9-4a8e-4432-8e6a-c5e4002ad5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b08fb-5245-415e-b3c2-b46f80de5a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30124422-dd37-456b-93ee-fff58decb067",
   "metadata": {},
   "outputs": [],
   "source": [
    "spy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc7a85a-51a0-4955-a31b-eef864cf08a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaab4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d33b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all string value for convertion Date to float\n",
    "dateColumn = df[\"Date\"]\n",
    "df[\"Date\"] = df[\"Date\"].str.replace(\"-\",'')\n",
    "df[\"Date\"] = pd.to_numeric(df['Date'], errors='coerce',downcast=\"integer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b20ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ef6eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c252ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a32fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696ba082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Linear Regression from scratch for predicting high, I'm going to add regularization to this - Guiller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a21f0",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "class LinearRegressionRegularization:\n",
    "    def __init__(self, max_iter=10,  learningRate=50, random_state=None):\n",
    "        self.max_iter_ = max_iter\n",
    "        self.alpha = learningRate\n",
    "        self.random_state_ = random_state\n",
    "        self.w_ = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "        self.w0 = 0\n",
    "        \n",
    "    def _split(self, X, y, ratio, random_state):\n",
    "        header = X.columns\n",
    "        # remove header for shuffling \n",
    "        x_data = X.values\n",
    "\n",
    "        random.seed(random_state)\n",
    "        train_ratio = ratio\n",
    "        test_ratio = 1 - train_ratio\n",
    "        \n",
    "        total_data_sample = len(X)\n",
    "        train_samples = int(total_data_sample * train_ratio)\n",
    "        test_samples = total_data_sample - train_samples\n",
    "\n",
    "        random.shuffle(x_data)\n",
    "        shuffled_data = pd.DataFrame(x_data, columns=header)\n",
    "\n",
    "        train_data = shuffled_data.head(train_samples)\n",
    "        test_data = shuffled_data.head(test_samples)\n",
    "        \n",
    "        return train_data, test_data\n",
    "        \n",
    "    def _predict(self, x_train, y_train):\n",
    "        #TO-DO : Add Regularization \n",
    "        \n",
    "        x_train_array = x_train.to_numpy()\n",
    "        m = len(y_train) # number of features \n",
    "        #Initial weights \n",
    "        tempWeights = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0] \n",
    "        tempW0 = 0\n",
    "        y_pred_btc = tempW0\n",
    "        \n",
    "        for idx in range (self.max_iter_): \n",
    "            for i in range (m):\n",
    "                summation = []\n",
    "                xi = x_train_array[i, :]\n",
    "                y_pred_btc = tempW0\n",
    "                for k in range (17):\n",
    "                    y_pred_btc += self.w_[k] * xi[k]\n",
    "                summation.append(y_pred_btc - y_train)\n",
    "\n",
    "                derivative = 2/m * sum(summation)\n",
    "                tempW0 = self.w0 - (self.alpha * derivative)\n",
    "\n",
    "            for j in range (17):\n",
    "                for i in range (m): \n",
    "                    summation = []\n",
    "                    xi = x_train_array[i, :]\n",
    "                    y_pred_btc = tempW0 \n",
    "                    for k in range (17):\n",
    "                        y_pred_btc += self.w_[k] * xi[k]  \n",
    "\n",
    "                    summation.append(y_pred_btc - y_train)\n",
    "                derivative = 2/m * sum(summation)\n",
    "                tempWeights.append(self.w_[j] - (self.alpha * derivative))    \n",
    "\n",
    "            #The previous iteration \n",
    "            last_17 = tempWeights[-17:]\n",
    "\n",
    "            #Assigning new weight values to old weights\n",
    "            for n in range (17):\n",
    "                tempWeights[n] = last_17[n]\n",
    "            self.w0 = tempW0\n",
    "            #next iteration\n",
    "\n",
    "        final_weights = tempWeights[:17]\n",
    "        self.w_ = final_weights\n",
    "        \n",
    "        return y_pred_btc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44569c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad236d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    \n",
    "    def _updateTrainingData(self, x_train):\n",
    "        for i in x_train.columns:\n",
    "            if i != 'Date':\n",
    "                x_train['yesterday_' +i] = x_train[i]\n",
    "                x_train['twoDaysAgo_' +i] = x_train[i]\n",
    "                x_train['threeDaysAgo_' +i] = x_train[i]\n",
    "                x_train['fourDaysAgo_' +i] = x_train[i]\n",
    "                x_train['fiveDaysAgo_' +i] = x_train[i]\n",
    "                x_train['sixDaysAgo_' +i] = x_train[i]\n",
    "                x_train['sevenDaysAgo_' +i] = x_train[i]\n",
    "                x_train['yesterday_' +i] = x_train['yesterday_' +i].shift(1)\n",
    "                x_train['twoDaysAgo_' +i] = x_train['twoDaysAgo_' +i].shift(2)\n",
    "                x_train['threeDaysAgo_' +i] = x_train['threeDaysAgo_' +i].shift(3)\n",
    "                x_train['fourDaysAgo_' +i] = x_train['fourDaysAgo_' +i].shift(4)\n",
    "                x_train['fiveDaysAgo_' +i] = x_train['fiveDaysAgo_' +i].shift(5)\n",
    "                x_train['sixDaysAgo_' +i] = x_train['sixDaysAgo_' +i].shift(6)\n",
    "                x_train['sevenDaysAgo_' +i] = x_train['sevenDaysAgo_' +i].shift(7)\n",
    "                x_train = x_train.drop(i, axis = 1)\n",
    "        return x_train\n",
    "    \n",
    "    def _updateDate(self, x_train):\n",
    "        x_train[\"Date\"]\n",
    "        x_train['Date'] = x_train['Date'].astype(str)\n",
    "        \n",
    "        for k in range (len(x_train[\"Date\"])):\n",
    "            size = len(x_train[\"Date\"][k])\n",
    "            string = x_train[\"Date\"][k]\n",
    "            substring_to_remove = \".0\"\n",
    "            x_train['Date'][k] = string.replace(substring_to_remove, \"\")\n",
    "\n",
    "        for k in range (len(x_train[\"Date\"])):\n",
    "            size = len(x_train[\"Date\"][k])\n",
    "            string = x_train[\"Date\"][k]\n",
    "            x_train['Date'][k] = string[:4] + \"-\" + string[4:]\n",
    "            #print(result)\n",
    "\n",
    "        for k in range (len(x_train[\"Date\"])):\n",
    "            size = len(x_train[\"Date\"][k])\n",
    "            string = x_train[\"Date\"][k]\n",
    "            x_train['Date'][k] = string[:7] + \"-\" + string[7:]\n",
    "        \n",
    "        return x_train['Date']\n",
    "    \n",
    "    def _replaceNanY(self, y_train):\n",
    "        column_means_7days =  y_train.tail(7).mean()\n",
    "        df_filled = y_train_btcHigh.fillna(column_means_7days)\n",
    "        y_train = df_filled\n",
    "        \n",
    "        return y_train\n",
    "    \n",
    "    def _replaceNanX(self, x_train):\n",
    "        column_means = x_train.mean()\n",
    "        df_filled = x_train.fillna(column_means)\n",
    "        x_train = df_filled\n",
    "        \n",
    "        return x_train\n",
    "    \n",
    "    def _newTrainingData(self, new_row, x_train):\n",
    "        x_train_temp = x_train.append(new_row, ignore_index=True)\n",
    "        return x_train_temp\n",
    "\n",
    "    \n",
    "    def _newTrainLabel(self, y_train):\n",
    "        column_means_7days = y_train.tail(7).mean()\n",
    "        new_row = pd.Series({'btcHigh': column_means_7days})\n",
    "        y_train_temp = y_train.append(new_row, ignore_index=True)\n",
    "        return y_train_temp\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3423c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionRegularization()\n",
    "utils = Utils()\n",
    "\n",
    "#Split the data for predicting High\n",
    "X = df\n",
    "y = df['btcHigh']\n",
    "\n",
    "# Split the data into training subsets\n",
    "train_data, test_data, = model._split(X, y, ratio=0.7, random_state=123 )\n",
    "X_train_btcHigh = train_data.drop(columns=['btcHigh'])\n",
    "y_train_btcHigh = train_data['btcHigh']\n",
    "\n",
    "#Adjust training data \n",
    "X_train_btcHigh = utils._updateTrainingData(X_train_btcHigh)\n",
    "X_train_btcHigh = utils._replaceNanX(X_train_btcHigh)\n",
    "\n",
    "has_nan = X_train_btcHigh.isna().any().any()\n",
    "\n",
    "if (has_nan != True):\n",
    "    #Predict\n",
    "    y_pred_btcHigh = model._predict(X_train_btcHigh, y_train_btcHigh)\n",
    "#else:\n",
    "    print (\"Training Data contains Nan values, \", has_nan)\n",
    "\n",
    "pd.options.mode.chained_assignment = None  #Hide warning\n",
    "X_train_btcHigh[\"Date\"] = utils._updateDate(X_train_btcHigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_train_btcHigh, y_pred_btcHigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b34e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual and predicted difference\n",
    "prediction_mse_df = pd.DataFrame({ 'Date': X_train_btcHigh['Date'], 'Actual High': y_train_btcHigh, 'Predicted High': y_pred_btcHigh, 'Difference': round(abs(y_train_btcHigh - y_pred_btcHigh),2)})\n",
    "prediction_mse_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f8b03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_train_btcHigh['Date'], y_train_btcHigh, color = 'b')\n",
    "plt.scatter(X_train_btcHigh['Date'], y_pred_btcHigh, color = 'r')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2642b0",
   "metadata": {},
   "source": [
    "### Predict the Future High Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae2d6f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegressionRegularization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m formatted_tomorrow \u001b[38;5;241m=\u001b[39m tomorrow\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m new_row \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m: formatted_tomorrow} \u001b[38;5;66;03m#predict tomorrow\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegressionRegularization()\n\u001b[1;32m      9\u001b[0m utils \u001b[38;5;241m=\u001b[39m Utils()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#New training data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LinearRegressionRegularization' is not defined"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "today = datetime.now().date()\n",
    "\n",
    "tomorrow = today + timedelta(days=1)\n",
    "formatted_tomorrow = tomorrow.strftime('%Y-%m-%d')\n",
    "new_row = {'Date': formatted_tomorrow} #predict tomorrow\n",
    "\n",
    "model = LinearRegressionRegularization()\n",
    "utils = Utils()\n",
    "\n",
    "#Split the data for predicting High\n",
    "X = df\n",
    "y = df['btcHigh']\n",
    "\n",
    "#New training data\n",
    "X = utils._newTrainingData(new_row, X)\n",
    "\n",
    "# Split the data into training subsets\n",
    "train_data, test_data, = model._split(X, y, ratio=0.7, random_state=123 )\n",
    "X_train_btcHigh = train_data.drop(columns=['btcHigh'])\n",
    "y_train_btcHigh = train_data['btcHigh']\n",
    "\n",
    "#Adjust training data \n",
    "\n",
    "X_train_btcHigh = utils._updateTrainingData(X_train_btcHigh)\n",
    "X_train_btcHigh = utils._replaceNanX(X_train_btcHigh)\n",
    "\n",
    "has_nan = X_train_btcHigh.isna().any().any()\n",
    "\n",
    "if (has_nan != True):\n",
    "    #Predict\n",
    "    y_pred_btcHigh = model._predict(X_train_btcHigh, y_train_btcHigh)\n",
    "#else:\n",
    "    print (\"Training Data contains Nan values, \", has_nan)\n",
    "\n",
    "pd.options.mode.chained_assignment = None  #Hide warning\n",
    "X_train_btcHigh[\"Date\"] = utils._updateDate(X_train_btcHigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0947306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_btcHigh.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a7db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_train_btcHigh['Date'], y_train_btcHigh, color = 'b')\n",
    "plt.scatter(X_train_btcHigh['Date'], y_pred_btcHigh, color = 'r')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_train_btcHigh, y_pred_btcHigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c9cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c628b0be-e6e9-498e-8359-c6a70a87cd03",
   "metadata": {},
   "source": [
    "When merged, around 600 or 30% of data got lost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb0652-a374-49ba-a716-18718d0db85d",
   "metadata": {},
   "source": [
    "## Graph - \n",
    "Guiller - I'm getting a conversion issue when computing the linear regression, so I converted the date to integer. That's why the graph is messed up. No need to fix the graph below, we will replace those with actual and prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76e912-6aad-470e-838e-2f1b2063b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATE'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf418cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "des = df.describe()\n",
    "exception = ['Date', 'DATE']\n",
    "for col in df.columns:\n",
    "    if col not in exception:\n",
    "        df[col] = (df[col] - des[col]['min']) / (des[col]['max'] - des[col]['min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5f12c-2fae-45e5-8ac1-1307faf03c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x = 'DATE', y = 'spyOpen', kind = 'scatter')\n",
    "df.plot(x = 'DATE', y = 'btcOpen', kind = 'scatter')\n",
    "df.plot(x = 'DATE', y = 'ethOpen', kind = 'scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d39d4ae-e367-4ab3-b18e-1a4c0f26de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['DATE'], df['spyOpen'], label = 'Spy Open')\n",
    "plt.plot(df['DATE'], df['btcOpen'], label = 'Bitcoin Open')\n",
    "plt.plot(df['DATE'], df['ethOpen'], label = 'Ethererum Open')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa31f29f-35b0-449a-b995-6e4d6f8996b4",
   "metadata": {},
   "source": [
    "Emphasize the need to normalization data, otherwise we cannot compare them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89040f8-8453-40ce-8328-0106525ab08b",
   "metadata": {},
   "source": [
    "# Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d19b68-5a1f-4be4-b799-1a60b9433fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b45e79-243b-4066-a7bb-3389ec47f574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d4b37-e776-482a-9d26-c32cece97f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0affd5-3403-4368-b42c-900bc8f2d89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['DATE'], df['spyOpen'], label = 'Spy Open')\n",
    "plt.plot(df['DATE'], df['btcOpen'], label = 'Bitcoin Open')\n",
    "plt.plot(df['DATE'], df['ethOpen'], label = 'Ethererum Open')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b5e373-598e-45f4-949e-02c4d81919cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d7f02b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
